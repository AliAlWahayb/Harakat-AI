{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc4b45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, Dense, Dropout, Bidirectional\n",
    "\n",
    "# Step 1: Load the dataset (your dataset with Harakat)\n",
    "# Assuming you have a CSV or txt file with two columns: \"Text_without_Harakat\" and \"Text_with_Harakat\"\n",
    "df = pd.read_csv('harakat_data.csv')\n",
    "\n",
    "# Step 2: Data Preprocessing\n",
    "# Function to preprocess the text (remove punctuation, normalize, etc.)\n",
    "def preprocess_text(text):\n",
    "    # Normalize Arabic text (remove tashkeel, punctuations, etc.)\n",
    "    text = text.replace(\"\n",
    "\", \" \").strip()\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing to both the columns\n",
    "df['Text_without_Harakat'] = df['Text_without_Harakat'].apply(preprocess_text)\n",
    "df['Text_with_Harakat'] = df['Text_with_Harakat'].apply(preprocess_text)\n",
    "\n",
    "# Step 3: Tokenization\n",
    "tokenizer = Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(df['Text_without_Harakat'].tolist() + df['Text_with_Harakat'].tolist())\n",
    "\n",
    "# Get the number of unique characters\n",
    "num_tokens = len(tokenizer.word_index) + 1  # Add 1 for padding\n",
    "\n",
    "# Convert text to sequence of tokens (characters)\n",
    "X = tokenizer.texts_to_sequences(df['Text_without_Harakat'].tolist())\n",
    "Y = tokenizer.texts_to_sequences(df['Text_with_Harakat'].tolist())\n",
    "\n",
    "# Padding the sequences to have the same length\n",
    "max_len = max([len(seq) for seq in X])  # Choose the maximum length of the sequences\n",
    "X_pad = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=max_len, padding='post')\n",
    "Y_pad = tf.keras.preprocessing.sequence.pad_sequences(Y, maxlen=max_len, padding='post')\n",
    "\n",
    "# Step 4: Data Splitting (Train and Validation)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_pad, Y_pad, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 5: Model Architecture\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_tokens, 128, input_length=max_len))\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_tokens, activation='softmax'))\n",
    "\n",
    "# Step 6: Compile the Model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Step 7: Model Training with Early Stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "history = model.fit(X_train, to_categorical(Y_train, num_tokens), epochs=10, batch_size=64, \n",
    "                    validation_data=(X_val, to_categorical(Y_val, num_tokens)), \n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# Step 8: Model Evaluation\n",
    "plt.plot(history.history['accuracy'], label='train accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Step 9: Inference (Prediction)\n",
    "def predict_harakat(text):\n",
    "    text_seq = tokenizer.texts_to_sequences([text])\n",
    "    text_pad = tf.keras.preprocessing.sequence.pad_sequences(text_seq, maxlen=max_len, padding='post')\n",
    "    pred = model.predict(text_pad)\n",
    "    pred_text = tokenizer.sequences_to_texts(np.argmax(pred, axis=-1))\n",
    "    return pred_text[0]\n",
    "\n",
    "# Test the model\n",
    "input_text = \"المدرسة\"\n",
    "predicted_text = predict_harakat(input_text)\n",
    "print(f\"Input: {input_text}\")\n",
    "print(f\"Predicted with Harakat: {predicted_text}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
